{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.core import Activation, Dense, Flatten, Dropout\n",
    "from keras.layers import Conv1D, AveragePooling1D, MaxPooling1D, BatchNormalization\n",
    "from keras.utils import np_utils \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import backend as K\n",
    "from keras.callbacks  import EarlyStopping\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.utils import class_weight\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# define variables and set values for network parameters\n",
    "#### network-related parameters\n",
    "runNum = 3\n",
    "nb_filters=[4, 4, 8]\n",
    "hidden_neuron_num = 8\n",
    "filter_size = 24\n",
    "channels = 3\n",
    "pool_size = 3\n",
    "strides= 4\n",
    "padding = 'same'\n",
    "nb_epoch = [50,25] \n",
    "learn_rate = 1e-2 \n",
    "batch_size = 120\n",
    "mtm=0.9\n",
    "nb_classes=5 ## number of classes is equal to the number of subjects\n",
    "borderMode = 'same'\n",
    "backend = 'tf'\n",
    "n_splits = 5 ## 5-fold cross validation\n",
    "\n",
    "##### evaluation metric (confusion matrix)\n",
    "conf_matrix = np.zeros([nb_classes, nb_classes, n_splits, runNum])\n",
    "conf_matrix_normalize = np.zeros([nb_classes, nb_classes, n_splits, runNum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### path to the base directory\n",
    "dataPath = 'path to data'\n",
    "savePath = 'path to save results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### load data and labels\n",
    "matContent = sio.loadmat(dataPath + 'data.mat')\n",
    "data = matContent['data']\n",
    "labels = matContent['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits = n_splits, shuffle = True) \n",
    "i = 0 ## fold counter\n",
    "\n",
    "## train the model on 4 folds and test it on the remained fold \n",
    "for train, test in kf.split(data, labels):     \n",
    "     trainingLabels = np_utils.to_categorical(labels[train], nb_classes) \n",
    "     print(\"TRAIN:\", train)\n",
    "     for r in range(runNum):\n",
    "        # Prepare network inputs\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=nb_filters[0], kernel_initializer='glorot_uniform', kernel_size=filter_size, padding=padding, activation='relu', input_shape =(data.shape[1], data.shape[2])))\n",
    "        model.add(AveragePooling1D(pool_size=pool_size, strides=strides, padding=padding))\n",
    "        model.add(BatchNormalization())        \n",
    "        \n",
    "        model.add(Conv1D(filters=nb_filters[1], kernel_size=filter_size, padding=padding, activation='relu', \n",
    "                 kernel_initializer='glorot_uniform')) \n",
    "        model.add(AveragePooling1D(pool_size=pool_size, strides=strides, padding=padding))\n",
    "        model.add(BatchNormalization())\n",
    "       \n",
    "        model.add(Conv1D(filters=nb_filters[2], kernel_size=filter_size, padding=padding, activation='relu', \n",
    "                  kernel_initializer='glorot_uniform')) \n",
    "        model.add(AveragePooling1D(pool_size=pool_size, strides=strides, padding=padding))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(hidden_neuron_num, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(nb_classes))\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "        for ep in range(len(nb_epoch)):\n",
    "            optimizer = SGD(lr=learn_rate / 10 ** ep, decay=5e-4, momentum=0.9)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "            model.fit(data[train], trainingLabels, batch_size=batch_size, \n",
    "                  epochs=nb_epoch[ep], verbose=2, callbacks=[earlyStopping], validation_split=0.1) \n",
    "                              \n",
    "        ############## model prediction and evaluation ##############\n",
    "       \n",
    "        predicted_testLabels = model.predict_classes(data[test],verbose = 0)\n",
    "        soft_targets_test = model.predict(data[test],verbose = 0)    \n",
    "        conf_matrix_normalize[:,:,i, r] = confusion_matrix(labels[test], predicted_testLabels, normalize = 'true')\n",
    "        conf_matrix[:,:,i, r] = confusion_matrix(labels[test], predicted_testLabels)\n",
    "        sio.savemat(savePath  +'results.mat', {'conf_matrix':conf_matrix, 'conf_matrix_normalize':conf_matrix_normalize})\n",
    "        \n",
    "     i+=1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
